{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RE -> ε-NFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isapt(c):\n",
    "    assert len(c) == 1\n",
    "    if ord(c) >= ord('a') and ord(c) <= ord('z') or ord(c) >= ord('A') and ord(c) <= ord('Z') or ord(c) >= ord('0') and ord(c) <= ord('9'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfast(org, top):\n",
    "    if org == '.' and top == '+':\n",
    "        return True\n",
    "    elif org == '*' and top != '*':\n",
    "        return True\n",
    "    return False\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, cn, cv, left=None, right=None):\n",
    "        # cn : 0:+ 1:. 2:* 3:symbols\n",
    "        self.cn = cn\n",
    "        self.cv = cv\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_ARR = [\"(a+b)*abb\", \"(b+a(aa*b)*b)*\" ,\"(b+aa+ac+aaa+aac)*\", \"(1+01)*00(0+1)*\" ,\"(0+1)*011\", \"(a+b)*\",\"ba*b\",\"(a+b)c\",\"a(bc)*\",\"son+bug*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.o.n+b.u.g*\n"
     ]
    }
   ],
   "source": [
    "indindind = 9\n",
    "RE = RE_ARR[indindind]\n",
    "RE = \"son+bug*\" #여기 RE입력!\n",
    "concatall = \"\"\n",
    "str_arr = []\n",
    "\n",
    "for i in range(len(RE)-1):\n",
    "    str_arr.append(RE[i])\n",
    "    if isapt(RE[i]):\n",
    "        if isapt(RE[i+1]) or RE[i+1] == '(':\n",
    "            str_arr.append('.')\n",
    "    if (RE[i] == ')' or RE[i] == '*') and (RE[i+1] == '(' or isapt(RE[i+1])):\n",
    "        str_arr.append('.')\n",
    "str_arr.append(RE[-1])\n",
    "concatall = \"\".join(str_arr)\n",
    "\n",
    "print(concatall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so.n.bu.g*.+\n"
     ]
    }
   ],
   "source": [
    "stack = []\n",
    "post_arr = []\n",
    "\n",
    "for c in concatall:\n",
    "    if isapt(c) or c == \"*\":\n",
    "        post_arr.append(c)\n",
    "    elif c == \")\":\n",
    "        while len(stack) > 0 and stack[-1] != \"(\":\n",
    "            post_arr.append(stack.pop())\n",
    "        stack.pop()\n",
    "    elif c == \"(\":\n",
    "        stack.append(c)\n",
    "    elif len(stack) == 0 or stack[-1] == \"(\" or isfast(c, stack[-1]):\n",
    "        \n",
    "        stack.append(c)\n",
    "    else:\n",
    "        while len(stack) > 0 and stack[-1] != \"(\" and not isfast(c, stack[-1]):\n",
    "            post_arr.append(stack.pop())\n",
    "        stack.append(c)\n",
    "while len(stack) > 0:\n",
    "    post_arr.append(stack.pop())\n",
    "\n",
    "postall = \"\".join(post_arr)\n",
    "print(postall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "for c in postall:\n",
    "        if c == \"+\":\n",
    "            nd = node(0,c)\n",
    "            nd.right = stack.pop()\n",
    "            nd.left = stack.pop()\n",
    "            stack.append(nd)\n",
    "        elif c == \".\":\n",
    "            nd = node(1,c)\n",
    "            nd.right = stack.pop()\n",
    "            nd.left = stack.pop()\n",
    "            stack.append(nd)\n",
    "        elif c == \"*\":\n",
    "            nd = node(2,c)\n",
    "            nd.left = stack.pop() \n",
    "            stack.append(nd)\n",
    "        elif c == \"(\" or c == \")\":\n",
    "            continue  \n",
    "        else:\n",
    "            stack.append(node(3,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eNFA:\n",
    "    def __init__(self):\n",
    "        self.next = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_plus(nd):\n",
    "    start = eNFA()\n",
    "    end = eNFA()\n",
    "\n",
    "    left_eNFA = node_filter(nd.left)\n",
    "    right_eNFA = node_filter(nd.right)\n",
    "\n",
    "    start.next['ε'] = [left_eNFA[0], right_eNFA[0]]\n",
    "    left_eNFA[1].next['ε'] = [end]\n",
    "    right_eNFA[1].next['ε'] = [end]\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def scan_dot(nd):\n",
    "    left_nfa  = node_filter(nd.left)\n",
    "    right_nfa = node_filter(nd.right)\n",
    "\n",
    "    left_nfa[1].next['ε'] = [right_nfa[0]]\n",
    "    return left_nfa[0], right_nfa[1]\n",
    "\n",
    "def scan_star(nd):\n",
    "    start = eNFA()\n",
    "    end = eNFA()\n",
    "\n",
    "    starred_nfa = node_filter(nd.left)\n",
    "\n",
    "    start.next['ε'] = [starred_nfa[0], end]\n",
    "    starred_nfa[1].next['ε'] = [starred_nfa[0], end]\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def scan_symbol(nd):\n",
    "    start = eNFA()\n",
    "    end = eNFA()\n",
    "    \n",
    "    start.next[nd.cv] = [end]\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_filter(nd):\n",
    "    if nd.cn == 0:\n",
    "        return scan_plus(nd)\n",
    "    elif nd.cn == 1:\n",
    "        return scan_dot(nd)\n",
    "    elif nd.cn == 2:\n",
    "        return scan_star(nd)\n",
    "    elif nd.cn == 3:\n",
    "        return scan_symbol(nd)\n",
    "    else:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "efas = node_filter(stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<__main__.eNFA object at 0x0000027F5EB98EE0>, <__main__.eNFA object at 0x0000027F5EB98F40>)\n"
     ]
    }
   ],
   "source": [
    "print(efas)\n",
    "enfa = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonbug_numbering(integer):\n",
    "    assert integer < 1000, \"too complicate RE\"\n",
    "    if integer > 99:\n",
    "        return str(integer)\n",
    "    elif integer > 9:\n",
    "        return \"0\" + str(integer)\n",
    "    else:\n",
    "        return \"00\"+str(integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_enfa(State, States_history, symbols):\n",
    "    if State in States_history:\n",
    "        return\n",
    "    States_history.append(State)\n",
    "    for sb in list(State.next):\n",
    "        if sb not in enfa['TerminalSet']:\n",
    "            enfa['TerminalSet'].add(sb)\n",
    "        for nest in State.next[sb]:\n",
    "            if nest not in symbols:\n",
    "                symbols[nest] = sorted(symbols.values())[-1]+1\n",
    "                qs = \"q\" + sonbug_numbering(symbols[nest])\n",
    "                enfa['StateSet'].add(qs)\n",
    "            if not (\"(q\"+sonbug_numbering(symbols[State])+\", \"+sb+\")\" in enfa['DeltaFunctions']):\n",
    "                enfa['DeltaFunctions'][\"(q\"+sonbug_numbering(symbols[State])+\", \"+sb+\")\"] = set()\n",
    "            enfa['DeltaFunctions'][\"(q\"+sonbug_numbering(symbols[State])+\", \"+sb+\")\"].add(\"q\"+sonbug_numbering(symbols[nest]))      \n",
    "        for nest in State.next[sb]:\n",
    "            make_enfa(nest, States_history, symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfa['StateSet'] = set()\n",
    "enfa['TerminalSet'] = set()\n",
    "enfa['DeltaFunctions'] = {}\n",
    "enfa['StartState'] = set()\n",
    "enfa['FinalStateSet'] = set()\n",
    "q_0 = \"q000\"\n",
    "enfa['StateSet'].add(q_0)\n",
    "make_enfa(efas[0], [], {efas[0]:0})\n",
    "    \n",
    "\n",
    "enfa[\"StartState\"].add(\"q000\")\n",
    "for st in list(enfa[\"StateSet\"]):\n",
    "    count = 0\n",
    "    for key,val in enfa['DeltaFunctions'].items():\n",
    "        for value in list(val):\n",
    "            if key[1:5] == st and value != st:\n",
    "                count += 1\n",
    "    if count == 0 and st not in enfa[\"FinalStateSet\"]:\n",
    "        enfa[\"FinalStateSet\"].add(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q008'}\n"
     ]
    }
   ],
   "source": [
    "print(enfa['FinalStateSet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./enfa\"+str(indindind+1)+\".json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(str(enfa), file, indent=\"\\t\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeltaFunctions': {'(q000, ε)': {'q001', 'q002'},\n",
      "                    '(q001, s)': {'q003'},\n",
      "                    '(q002, b)': {'q009'},\n",
      "                    '(q003, ε)': {'q004'},\n",
      "                    '(q004, o)': {'q005'},\n",
      "                    '(q005, ε)': {'q006'},\n",
      "                    '(q006, n)': {'q007'},\n",
      "                    '(q007, ε)': {'q008'},\n",
      "                    '(q009, ε)': {'q010'},\n",
      "                    '(q010, u)': {'q011'},\n",
      "                    '(q011, ε)': {'q012'},\n",
      "                    '(q012, ε)': {'q014', 'q013'},\n",
      "                    '(q013, g)': {'q015'},\n",
      "                    '(q014, ε)': {'q008'},\n",
      "                    '(q015, ε)': {'q014', 'q013'}},\n",
      " 'FinalStateSet': {'q008'},\n",
      " 'StartState': {'q000'},\n",
      " 'StateSet': {'q000',\n",
      "              'q001',\n",
      "              'q002',\n",
      "              'q003',\n",
      "              'q004',\n",
      "              'q005',\n",
      "              'q006',\n",
      "              'q007',\n",
      "              'q008',\n",
      "              'q009',\n",
      "              'q010',\n",
      "              'q011',\n",
      "              'q012',\n",
      "              'q013',\n",
      "              'q014',\n",
      "              'q015'},\n",
      " 'TerminalSet': {'s', 'g', 'ε', 'o', 'b', 'u', 'n'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pprint(enfa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ε-NFA -> DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listunion(list1, list2):\n",
    "    return sorted(list(set(list1) | set(list2)))\n",
    "\n",
    "def get_enfa_delta(state, input):\n",
    "    if \"(\"+state+\", \"+input+\")\" in enfa['DeltaFunctions'].keys():\n",
    "        return enfa['DeltaFunctions'][\"(\"+state+\", \"+input+\")\"]\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['StateSet'] = set()\n",
    "dfa['TerminalSet'] = set()\n",
    "dfa['DeltaFunctions'] = {}\n",
    "dfa['StartState'] = set()\n",
    "dfa['FinalStateSet'] = set()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "candidate = []\n",
    "\n",
    "\n",
    "for state in enfa['StateSet']: \n",
    "    for sigma in enfa['TerminalSet']:\n",
    "        if sigma != 'ε':\n",
    "            continue\n",
    "        q_temp = []\n",
    "        \n",
    "        for key,val in enfa['DeltaFunctions'].items():\n",
    "            for value in val:\n",
    "                start = key[1:5]\n",
    "                inp = key[7]\n",
    "                end = value\n",
    "                if state == start and sigma == inp:\n",
    "                    if end not in q_temp:\n",
    "                        q_temp.append(end)\n",
    "        if not len(q_temp):\n",
    "            continue\n",
    "        q_states = []\n",
    "        \n",
    "        q_states.append(state)\n",
    "        q_states = sorted(q_states)\n",
    "        q_temp = sorted(q_temp)\n",
    "        candidate.append([q_states, sigma, q_temp])    \n",
    "\n",
    "\n",
    "e_match = {}\n",
    "\n",
    "\n",
    "for i in enfa['StateSet']:\n",
    "    e_match[tuple([i])] = [i]\n",
    "\n",
    "\n",
    "no_change = False\n",
    "while not no_change:\n",
    "    no_change = True\n",
    "    for delta in candidate: #single\n",
    "        if len(delta[0]) == 1 and delta[1] == 'ε' and len(e_match[tuple(delta[0])]) == 1:\n",
    "            e_match[tuple(delta[0])] = e_match[tuple(delta[0])]+delta[2] # ('q000',) : [\"q001\",\"q002\"]\n",
    "            if delta[0][0] not in e_match[tuple(delta[0])]: #본인 넣는다.\n",
    "                e_match[tuple(delta[0])].append(delta[0][0])\n",
    "            no_change = False\n",
    "        if len(delta[0]) == 1 and delta[1] == 'ε':\n",
    "            temp = deepcopy(e_match[tuple(delta[0])])\n",
    "            \n",
    "            for get in e_match[tuple(delta[0])]:\n",
    "                \n",
    "                if (get,) in e_match.keys(): \n",
    "                    temp = listunion(e_match[(get,)],temp)     \n",
    "            if len(temp) > len(e_match[tuple(delta[0])]):\n",
    "                e_match[tuple(delta[0])] = deepcopy(temp) \n",
    "                no_change = False\n",
    "\n",
    "def multcandidate(states):\n",
    "\n",
    "    for sigma in enfa['TerminalSet']:\n",
    "        if sigma != 'ε':\n",
    "            continue\n",
    "        q_temp = []\n",
    "        for state in states:\n",
    "            for key,val in enfa['DeltaFunctions'].items():\n",
    "                for value in val:\n",
    "                    start = key[1:5]\n",
    "                    inp = key[7]\n",
    "                    end = value\n",
    "                    if state == start and sigma == inp:\n",
    "                        if end not in q_temp:\n",
    "                            q_temp.append(end)\n",
    "        if not len(q_temp):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        q_states = states\n",
    "        q_states = sorted(q_states)\n",
    "        q_temp = sorted(q_temp)\n",
    "        candidate.append([q_states, sigma, q_temp])  \n",
    "\n",
    "    no_change = False\n",
    "    while not no_change:\n",
    "        no_change = True\n",
    "        for delta in candidate: #mult\n",
    "            \n",
    "            if len(delta[0]) != 1 and delta[1] == 'ε' and tuple(delta[0]) not in e_match.keys():\n",
    "                e_match[tuple(delta[0])] = deepcopy(delta[2]) # ('q000','q001') : [\"q001\",\"q002\"]\n",
    "                no_change = False\n",
    "            if len(delta[0]) != 1 and delta[1] == 'ε':\n",
    "                temp = deepcopy(e_match[tuple(delta[0])])\n",
    "                for d in delta[0]:\n",
    "                    for get in e_match[(d,)]:\n",
    "                        if (get,) in e_match.keys(): \n",
    "                            temp=listunion(e_match[(get,)],temp)\n",
    "                if len(temp) > len(e_match[tuple(delta[0])]):\n",
    "                    e_match[tuple(delta[0])] = deepcopy(temp) \n",
    "                    no_change = False\n",
    "\n",
    "\n",
    "\n",
    "new_candidate = []\n",
    "for ss in enfa['StartState']:\n",
    "    dfa['StartState'].add(tuple(sorted(e_match[(ss,)])))\n",
    "    dfa['StateSet'].add(tuple(sorted(e_match[(ss,)])))\n",
    "    no_change = False\n",
    "    have_to_do = []\n",
    "    have_to_do.append((ss,))\n",
    "    while len(have_to_do):\n",
    "        tg = have_to_do.pop()\n",
    "        \n",
    "        for sigma in enfa['TerminalSet']:\n",
    "            if sigma == 'ε':\n",
    "                continue\n",
    "            after_closer_result = []\n",
    "            \n",
    "            if tuple(tg) not in e_match.keys():\n",
    "                \n",
    "                multcandidate(tg)\n",
    "\n",
    "            for ecs in e_match[tuple(tg)]:\n",
    "                \n",
    "                result = get_enfa_delta(ecs, sigma)\n",
    "                if result:\n",
    "\n",
    "                    for r in result:\n",
    "                        if (r,) in e_match.keys():\n",
    "                            after_closer_result = listunion(after_closer_result, e_match[(r,)])\n",
    "            if not len(after_closer_result): # 결과가 없을떄\n",
    "                continue \n",
    "            if tuple(after_closer_result) not in dfa['StateSet']:\n",
    "                dfa['StateSet'].add(tuple(after_closer_result))\n",
    "                have_to_do.append(after_closer_result)\n",
    "            new_candidate.append([sorted(e_match[tuple(tg)]),sigma,sorted(after_closer_result)])\n",
    "\n",
    "\n",
    "\n",
    "for states in dfa['StateSet']:\n",
    "    for state in states:\n",
    "        if state in enfa['FinalStateSet'] and states not in dfa['FinalStateSet']:\n",
    "            dfa['FinalStateSet'].add(states)\n",
    "\n",
    "enfa['TerminalSet'].remove('ε')\n",
    "dfa['TerminalSet'] = deepcopy(enfa['TerminalSet'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['q000', 'q001', 'q002'], 's', ['q003', 'q004']],\n",
      " [['q000', 'q001', 'q002'], 'b', ['q009', 'q010']],\n",
      " [['q009', 'q010'], 'u', ['q008', 'q011', 'q012', 'q013', 'q014']],\n",
      " [['q008', 'q011', 'q012', 'q013', 'q014'],\n",
      "  'g',\n",
      "  ['q008', 'q013', 'q014', 'q015']],\n",
      " [['q008', 'q013', 'q014', 'q015'], 'g', ['q008', 'q013', 'q014', 'q015']],\n",
      " [['q003', 'q004'], 'o', ['q005', 'q006']],\n",
      " [['q005', 'q006'], 'n', ['q007', 'q008']]]\n"
     ]
    }
   ],
   "source": [
    "pprint(new_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('q008', 'q011', 'q012', 'q013', 'q014'): 'q000', ('q007', 'q008'): 'q001', ('q008', 'q013', 'q014', 'q015'): 'q002', ('q005', 'q006'): 'q003', ('q003', 'q004'): 'q004', ('q009', 'q010'): 'q005', ('q000', 'q001', 'q002'): 'q006'}\n"
     ]
    }
   ],
   "source": [
    "reduce_table = {}\n",
    "for i,v in enumerate(dfa['StateSet']):\n",
    "    val = \"q\"+sonbug_numbering(i)\n",
    "    reduce_table[v] = val\n",
    "print(reduce_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "for delta in new_candidate:\n",
    "    dfa['DeltaFunctions'][\"(\"+reduce_table[tuple(sorted(delta[0]))]+\", \"+delta[1]+\")\"] = {reduce_table[tuple(sorted(delta[2]))]}\n",
    "\n",
    "sett = set()\n",
    "sett.add(reduce_table[list(dfa['StartState'])[0]])\n",
    "\n",
    "dfa['StartState'] = deepcopy(sett)\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for state in dfa['StateSet']:\n",
    "    sett.add(reduce_table[state])\n",
    "    \n",
    "dfa['StateSet'] = deepcopy(sett)\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for state in dfa['FinalStateSet']:\n",
    "    sett.add(reduce_table[state])\n",
    "dfa['FinalStateSet'] = sett\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('q015',): ['q008', 'q013', 'q014', 'q015'], ('q006',): ['q006'], ('q008',): ['q008'], ('q009',): ['q009', 'q010'], ('q007',): ['q007', 'q008'], ('q001',): ['q001'], ('q012',): ['q008', 'q012', 'q013', 'q014'], ('q011',): ['q008', 'q011', 'q012', 'q013', 'q014'], ('q000',): ['q000', 'q001', 'q002'], ('q010',): ['q010'], ('q014',): ['q014', 'q008'], ('q004',): ['q004'], ('q002',): ['q002'], ('q005',): ['q005', 'q006'], ('q003',): ['q003', 'q004'], ('q013',): ['q013'], ('q009', 'q010'): ['q009', 'q010'], ('q008', 'q011', 'q012', 'q013', 'q014'): ['q008', 'q011', 'q012', 'q013', 'q014'], ('q008', 'q013', 'q014', 'q015'): ['q008', 'q013', 'q014', 'q015'], ('q003', 'q004'): ['q003', 'q004'], ('q005', 'q006'): ['q005', 'q006'], ('q007', 'q008'): ['q007', 'q008']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(e_match)\n",
    "e_m = deepcopy(e_match)\n",
    "for i in e_match.keys():\n",
    "    e_m[str(i)] = e_m.pop(i)\n",
    "with open(\"./e_closer.json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(e_m, file, indent=\"\\t\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q006'}\n",
      "{'q001', 'q002', 'q000'}\n"
     ]
    }
   ],
   "source": [
    "pprint(dfa['StartState'])\n",
    "pprint(dfa['FinalStateSet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dfa\"+str(indindind+1)+\".json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(str(dfa), file, indent=\"\\t\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeltaFunctions': {'(q000, g)': {'q002'},\n",
      "                    '(q002, g)': {'q002'},\n",
      "                    '(q003, n)': {'q001'},\n",
      "                    '(q004, o)': {'q003'},\n",
      "                    '(q005, u)': {'q000'},\n",
      "                    '(q006, b)': {'q005'},\n",
      "                    '(q006, s)': {'q004'}},\n",
      " 'FinalStateSet': {'q001', 'q002', 'q000'},\n",
      " 'StartState': {'q006'},\n",
      " 'StateSet': {'q006', 'q001', 'q000', 'q004', 'q002', 'q005', 'q003'},\n",
      " 'TerminalSet': {'g', 's', 'o', 'b', 'u', 'n'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dfa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFA -> reduced DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfa_delta(state, input):\n",
    "    if \"(\"+state+\", \"+input+\")\" in dfa['DeltaFunctions'].keys():\n",
    "        return list(dfa['DeltaFunctions'][\"(\"+state+\", \"+input+\")\"])[0]\n",
    "    return \"-1\"\n",
    "\n",
    "def something_in_list(something, list):\n",
    "    if something in list:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def combine_same_inlist(lst):\n",
    "    pass\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['q006'], ['q005'], ['q003'], ['q004'], ['q000', 'q002'], ['q001']]\n",
      "[defaultdict(<class 'list'>, {'NNN003NNN001NNNNNN': ['q006']}), defaultdict(<class 'list'>, {'NNNNNNNNNNNN004NNN': ['q005']}), defaultdict(<class 'list'>, {'NNNNNNNNNNNNNNN005': ['q003']}), defaultdict(<class 'list'>, {'NNNNNN002NNNNNNNNN': ['q004']}), defaultdict(<class 'list'>, {'004NNNNNNNNNNNNNNN': ['q000', 'q002']}), defaultdict(<class 'list'>, {'NNNNNNNNNNNNNNNNNN': ['q001']})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "getarr=sorted(list(dfa['StateSet']))\n",
    "\n",
    "arr = [list(dfa['StateSet'] - dfa['FinalStateSet']),sorted(list(dfa['FinalStateSet']))]\n",
    "LEN_STATE = len(dfa['StateSet'])\n",
    "checkarr = [[\"I\"]*len(dfa['TerminalSet']) for _ in range(LEN_STATE)]\n",
    "\n",
    "for i in range(LEN_STATE+1):\n",
    "    lenarr = len(arr)\n",
    "    for j in range(LEN_STATE):\n",
    "        for ki,kv in enumerate(dfa['TerminalSet']):\n",
    "            anstr=get_dfa_delta(getarr[j],kv)\n",
    "            \n",
    "            \n",
    "            if anstr==\"-1\":\n",
    "                checkarr[j][ki] = \"NNN\"\n",
    "            else:\n",
    "                for mi,mv in enumerate(arr):\n",
    "                    if something_in_list(anstr,mv):\n",
    "                        checkarr[j][ki] = sonbug_numbering(mi)\n",
    "    temp_arr = []\n",
    "\n",
    "    \n",
    "    big_ddic = []\n",
    "    for ji,jv in enumerate(arr):\n",
    "        ddic = defaultdict(list)\n",
    "        for ki,kv in enumerate(jv):\n",
    "            sumstr = \"\"\n",
    "            for m in checkarr[int(kv[1:])]:\n",
    "                sumstr += m\n",
    "            ddic[sumstr].append(kv)\n",
    "        \n",
    "        for key,val in ddic.items():\n",
    "            temp_arr.append(val)\n",
    "        big_ddic.append(deepcopy(ddic))\n",
    "        \n",
    "\n",
    "\n",
    "    arr = deepcopy(temp_arr)    \n",
    "    \n",
    "    \n",
    "    if lenarr == len(arr):\n",
    "        print(arr)\n",
    "        print(big_ddic)\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbstr_slicing(k,ji):\n",
    "    return k[ji*3 : ji*3+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['q006'], 's', ['q004']], [['q006'], 'b', ['q005']], [['q005'], 'u', ['q000', 'q002']], [['q003'], 'n', ['q001']], [['q004'], 'o', ['q003']], [['q000', 'q002'], 'g', ['q000', 'q002']]]\n"
     ]
    }
   ],
   "source": [
    "new_candidate = []\n",
    "for i in big_ddic:\n",
    "    for k,v in i.items():\n",
    "        for ji,jv in enumerate(dfa['TerminalSet']):\n",
    "            #v가 jv를 보고 arr[k[ji]]로 이동한다는 것임\n",
    "            if sbstr_slicing(k,ji)!=\"NNN\":\n",
    "                new_candidate.append([v,jv,arr[int(sbstr_slicing(k,ji))]])\n",
    "print(new_candidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('q006',): 'q000', ('q005',): 'q001', ('q003',): 'q002', ('q004',): 'q003', ('q000', 'q002'): 'q004', ('q001',): 'q005'}\n"
     ]
    }
   ],
   "source": [
    "rdfa = {}\n",
    "rdfa['StateSet'] = set()\n",
    "rdfa['TerminalSet'] = deepcopy(dfa['TerminalSet'])\n",
    "rdfa['DeltaFunctions'] = {}\n",
    "rdfa['StartState'] = set()\n",
    "rdfa['FinalStateSet'] = set()\n",
    "\n",
    "reduce_table = {}\n",
    "for i,v in enumerate(arr):\n",
    "    val = \"q\"+sonbug_numbering(i)\n",
    "    reduce_table[tuple(v)] = val\n",
    "print(reduce_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "for delta in new_candidate:\n",
    "    rdfa['DeltaFunctions'][\"(\"+reduce_table[tuple(delta[0])]+\", \"+delta[1]+\")\"] = {reduce_table[tuple(delta[2])]}\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for states in arr:\n",
    "    sett.add(reduce_table[tuple(states)])\n",
    "\n",
    "rdfa['StateSet'] = deepcopy(sett)\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for ss in dfa['StartState']:\n",
    "    for k,v in reduce_table.items():\n",
    "        if ss in k:\n",
    "            sett.add(v)\n",
    "\n",
    "rdfa['StartState'] = deepcopy(sett)\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for fs in dfa['FinalStateSet']:\n",
    "    for k,v in reduce_table.items():\n",
    "        if fs in k:\n",
    "            sett.add(v)\n",
    "\n",
    "rdfa['FinalStateSet'] = deepcopy(sett)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./rdfa\"+str(indindind+1)+\".json\", 'w', encoding='utf-8') as file:\n",
    "    json.dump(str(rdfa), file, indent=\"\\t\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeltaFunctions': {'(q000, b)': {'q001'},\n",
      "                    '(q000, s)': {'q003'},\n",
      "                    '(q001, u)': {'q004'},\n",
      "                    '(q002, n)': {'q005'},\n",
      "                    '(q003, o)': {'q002'},\n",
      "                    '(q004, g)': {'q004'}},\n",
      " 'FinalStateSet': {'q005', 'q004'},\n",
      " 'StartState': {'q000'},\n",
      " 'StateSet': {'q001', 'q000', 'q004', 'q002', 'q005', 'q003'},\n",
      " 'TerminalSet': {'s', 'g', 'o', 'b', 'u', 'n'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(rdfa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
