{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RE -> ε-NFA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a+b)*abb\n",
    "( recognize ( push , a recognize check len(stack) check stack[-1]+ a push ,+ push(just push) , b recognize check len(stack) check stack[-1]+ stack pop+ b push stack push+ , ) traverse until ( reveals check stack[index'('-1]+ check index'('0 pop all(just concat) , * check len(stack) write , a check len(stack)write, b write, b write\n",
    "\n",
    "(b+a(aa*b)*b)* \n",
    "( recognize ( push, b recognize check len(stack) check stack[-1]+ b push , + push , a recognize check len(stack) check stack[-1]+ +pop \n",
    "\n",
    "\n",
    "(b+aa+ac+aaa+aac)*\n",
    "\n",
    "(1+01)*00(0+1)*\n",
    "\n",
    "(0+1)*011  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isapt(c):\n",
    "    assert len(c) == 1\n",
    "    if ord(c) >= ord('a') and ord(c) <= ord('z') or ord(c) >= ord('A') and ord(c) <= ord('Z') or ord(c) >= ord('0') and ord(c) <= ord('9'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfast(org, top):\n",
    "    if org == '.' and top == '+':\n",
    "        return True\n",
    "    elif org == '*' and top != '*':\n",
    "        return True\n",
    "    return False\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, cn, cv, left=None, right=None):\n",
    "        # cn : 0:+ 1:. 2:* 3:symbols\n",
    "        self.cn = cn\n",
    "        self.cv = cv\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_ARR = [\"(a+b)*abb\", \"(b+a(aa*b)*b)*\" ,\"(b+aa+ac+aaa+aac)*\", \"(1+01)*00(0+1)*\" ,\"(0+1)*011\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b+a.(a.a*.b)*.b)*\n"
     ]
    }
   ],
   "source": [
    "RE = RE_ARR[0]\n",
    "RE = \"(b+a(aa*b)*b)*\" #여기 RE입력!\n",
    "concatall = \"\"\n",
    "str_arr = []\n",
    "\n",
    "for i in range(len(RE)-1):\n",
    "    str_arr.append(RE[i])\n",
    "    if isapt(RE[i]):\n",
    "        if isapt(RE[i+1]) or RE[i+1] == '(':\n",
    "            str_arr.append('.')\n",
    "    if (RE[i] == ')' or RE[i] == '*') and (RE[i+1] == '(' or isapt(RE[i+1])):\n",
    "        str_arr.append('.')\n",
    "str_arr.append(RE[-1])\n",
    "concatall = \"\".join(str_arr)\n",
    "\n",
    "print(concatall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baaa*.b.*.b.+*\n"
     ]
    }
   ],
   "source": [
    "stack = []\n",
    "post_arr = []\n",
    "\n",
    "for c in concatall:\n",
    "    if isapt(c) or c == \"*\":\n",
    "        post_arr.append(c)\n",
    "    elif c == \")\":\n",
    "        while len(stack) > 0 and stack[-1] != \"(\":\n",
    "            post_arr.append(stack.pop())\n",
    "        stack.pop()\n",
    "    elif c == \"(\":\n",
    "        stack.append(c)\n",
    "    elif len(stack) == 0 or stack[-1] == \"(\" or isfast(c, stack[-1]):\n",
    "        \n",
    "        stack.append(c)\n",
    "    else:\n",
    "        while len(stack) > 0 and stack[-1] != \"(\" and not isfast(c, stack[-1]):\n",
    "            post_arr.append(stack.pop())\n",
    "        stack.append(c)\n",
    "while len(stack) > 0:\n",
    "    post_arr.append(stack.pop())\n",
    "\n",
    "postall = \"\".join(post_arr)\n",
    "print(postall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "for c in postall:\n",
    "        if c == \"+\":\n",
    "            nd = node(0,c)\n",
    "            nd.right = stack.pop()\n",
    "            nd.left = stack.pop()\n",
    "            stack.append(nd)\n",
    "        elif c == \".\":\n",
    "            nd = node(1,c)\n",
    "            nd.right = stack.pop()\n",
    "            nd.left = stack.pop()\n",
    "            stack.append(nd)\n",
    "        elif c == \"*\":\n",
    "            nd = node(2,c)\n",
    "            nd.left = stack.pop() \n",
    "            stack.append(nd)\n",
    "        elif c == \"(\" or c == \")\":\n",
    "            continue  \n",
    "        else:\n",
    "            stack.append(node(3,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eNFA:\n",
    "    def __init__(self):\n",
    "        self.next = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_plus(nd):\n",
    "    start = eNFA()\n",
    "    end = eNFA()\n",
    "\n",
    "    left_eNFA = node_filter(nd.left)\n",
    "    right_eNFA = node_filter(nd.right)\n",
    "\n",
    "    start.next['ε'] = [left_eNFA[0], right_eNFA[0]]\n",
    "    left_eNFA[1].next['ε'] = [end]\n",
    "    right_eNFA[1].next['ε'] = [end]\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def scan_dot(nd):\n",
    "    left_nfa  = node_filter(nd.left)\n",
    "    right_nfa = node_filter(nd.right)\n",
    "\n",
    "    left_nfa[1].next['ε'] = [right_nfa[0]]\n",
    "    return left_nfa[0], right_nfa[1]\n",
    "\n",
    "def scan_star(nd):\n",
    "    start = eNFA()\n",
    "    end = eNFA()\n",
    "\n",
    "    starred_nfa = node_filter(nd.left)\n",
    "\n",
    "    start.next['ε'] = [starred_nfa[0], end]\n",
    "    starred_nfa[1].next['ε'] = [starred_nfa[0], end]\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def scan_symbol(nd):\n",
    "    start = eNFA()\n",
    "    end = eNFA()\n",
    "    \n",
    "    start.next[nd.cv] = [end]\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_filter(nd):\n",
    "    if nd.cn == 0:\n",
    "        return scan_plus(nd)\n",
    "    elif nd.cn == 1:\n",
    "        return scan_dot(nd)\n",
    "    elif nd.cn == 2:\n",
    "        return scan_star(nd)\n",
    "    elif nd.cn == 3:\n",
    "        return scan_symbol(nd)\n",
    "    else:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "efas = node_filter(stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<__main__.eNFA object at 0x7f9e582f1eb0>, <__main__.eNFA object at 0x7f9e582f19a0>)\n"
     ]
    }
   ],
   "source": [
    "print(efas)\n",
    "enfa = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonbug_numbering(integer):\n",
    "    assert integer < 1000, \"too complicate RE\"\n",
    "    if integer > 99:\n",
    "        return str(integer)\n",
    "    elif integer > 9:\n",
    "        return \"0\" + str(integer)\n",
    "    else:\n",
    "        return \"00\"+str(integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_enfa(State, States_history, symbols):\n",
    "    if State in States_history:\n",
    "        return\n",
    "    States_history.append(State)\n",
    "    for sb in list(State.next):\n",
    "        if sb not in enfa['TerminalSet']:\n",
    "            enfa['TerminalSet'].add(sb)\n",
    "        for nest in State.next[sb]:\n",
    "            if nest not in symbols:\n",
    "                symbols[nest] = sorted(symbols.values())[-1]+1\n",
    "                qs = \"q\" + sonbug_numbering(symbols[nest])\n",
    "                enfa['StateSet'].add(qs)\n",
    "            if not (\"(q\"+sonbug_numbering(symbols[State])+\", \"+sb+\")\" in enfa['DeltaFunctions']):\n",
    "                enfa['DeltaFunctions'][\"(q\"+sonbug_numbering(symbols[State])+\", \"+sb+\")\"] = set()\n",
    "            enfa['DeltaFunctions'][\"(q\"+sonbug_numbering(symbols[State])+\", \"+sb+\")\"].add(\"q\"+sonbug_numbering(symbols[nest]))      \n",
    "        for nest in State.next[sb]:\n",
    "            make_enfa(nest, States_history, symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfa['StateSet'] = set()\n",
    "enfa['TerminalSet'] = set()\n",
    "enfa['DeltaFunctions'] = {}\n",
    "enfa['StartState'] = set()\n",
    "enfa['FinalStateSet'] = set()\n",
    "q_0 = \"q000\"\n",
    "enfa['StateSet'].add(q_0)\n",
    "make_enfa(efas[0], [], {efas[0]:0})\n",
    "    \n",
    "\n",
    "enfa[\"StartState\"].add(\"q000\")\n",
    "for st in list(enfa[\"StateSet\"]):\n",
    "    count = 0\n",
    "    for key,val in enfa['DeltaFunctions'].items():\n",
    "        for value in list(val):\n",
    "            if key[1:5] == st and value != st:\n",
    "                count += 1\n",
    "    if count == 0 and st not in enfa[\"FinalStateSet\"]:\n",
    "        enfa[\"FinalStateSet\"].add(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StateSet': {'q018', 'q004', 'q009', 'q016', 'q017', 'q002', 'q007', 'q010', 'q013', 'q003', 'q008', 'q015', 'q006', 'q014', 'q005', 'q011', 'q000', 'q019', 'q001', 'q012'}, 'TerminalSet': {'b', 'ε', 'a'}, 'DeltaFunctions': {'(q000, ε)': {'q002', 'q001'}, '(q001, ε)': {'q004', 'q003'}, '(q003, b)': {'q005'}, '(q005, ε)': {'q006'}, '(q006, ε)': {'q002', 'q001'}, '(q004, a)': {'q007'}, '(q007, ε)': {'q008'}, '(q008, ε)': {'q010', 'q009'}, '(q009, a)': {'q011'}, '(q011, ε)': {'q012'}, '(q012, ε)': {'q014', 'q013'}, '(q013, a)': {'q015'}, '(q015, ε)': {'q014', 'q013'}, '(q014, ε)': {'q016'}, '(q016, b)': {'q017'}, '(q017, ε)': {'q010', 'q009'}, '(q010, ε)': {'q018'}, '(q018, b)': {'q019'}, '(q019, ε)': {'q006'}}, 'StartState': {'q000'}, 'FinalStateSet': {'q002'}}\n"
     ]
    }
   ],
   "source": [
    "print(enfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeltaFunctions': {'(q000, ε)': {'q002', 'q001'},\n",
      "                    '(q001, ε)': {'q004', 'q003'},\n",
      "                    '(q003, b)': {'q005'},\n",
      "                    '(q004, a)': {'q007'},\n",
      "                    '(q005, ε)': {'q006'},\n",
      "                    '(q006, ε)': {'q002', 'q001'},\n",
      "                    '(q007, ε)': {'q008'},\n",
      "                    '(q008, ε)': {'q010', 'q009'},\n",
      "                    '(q009, a)': {'q011'},\n",
      "                    '(q010, ε)': {'q018'},\n",
      "                    '(q011, ε)': {'q012'},\n",
      "                    '(q012, ε)': {'q014', 'q013'},\n",
      "                    '(q013, a)': {'q015'},\n",
      "                    '(q014, ε)': {'q016'},\n",
      "                    '(q015, ε)': {'q014', 'q013'},\n",
      "                    '(q016, b)': {'q017'},\n",
      "                    '(q017, ε)': {'q010', 'q009'},\n",
      "                    '(q018, b)': {'q019'},\n",
      "                    '(q019, ε)': {'q006'}},\n",
      " 'FinalStateSet': {'q002'},\n",
      " 'StartState': {'q000'},\n",
      " 'StateSet': {'q000',\n",
      "              'q001',\n",
      "              'q002',\n",
      "              'q003',\n",
      "              'q004',\n",
      "              'q005',\n",
      "              'q006',\n",
      "              'q007',\n",
      "              'q008',\n",
      "              'q009',\n",
      "              'q010',\n",
      "              'q011',\n",
      "              'q012',\n",
      "              'q013',\n",
      "              'q014',\n",
      "              'q015',\n",
      "              'q016',\n",
      "              'q017',\n",
      "              'q018',\n",
      "              'q019'},\n",
      " 'TerminalSet': {'b', 'ε', 'a'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(enfa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ε-NFA -> DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listunion(list1, list2):\n",
    "    return sorted(list(set(list1) | set(list2)))\n",
    "\n",
    "def get_enfa_delta(state, input):\n",
    "    if \"(\"+state+\", \"+input+\")\" in enfa['DeltaFunctions'].keys():\n",
    "        return enfa['DeltaFunctions'][\"(\"+state+\", \"+input+\")\"]\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['StateSet'] = set()\n",
    "dfa['TerminalSet'] = set()\n",
    "dfa['DeltaFunctions'] = {}\n",
    "dfa['StartState'] = set()\n",
    "dfa['FinalStateSet'] = set()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "candidate = []\n",
    "\n",
    "\n",
    "for state in enfa['StateSet']: \n",
    "    for sigma in enfa['TerminalSet']:\n",
    "        if sigma != 'ε':\n",
    "            continue\n",
    "        q_temp = []\n",
    "        \n",
    "        for key,val in enfa['DeltaFunctions'].items():\n",
    "            for value in val:\n",
    "                start = key[1:5]\n",
    "                inp = key[7]\n",
    "                end = value\n",
    "                if state == start and sigma == inp:\n",
    "                    if end not in q_temp:\n",
    "                        q_temp.append(end)\n",
    "        if not len(q_temp):\n",
    "            continue\n",
    "        q_states = []\n",
    "        \n",
    "        q_states.append(state)\n",
    "        q_states = sorted(q_states)\n",
    "        q_temp = sorted(q_temp)\n",
    "        candidate.append([q_states, sigma, q_temp])    \n",
    "\n",
    "\n",
    "e_match = {}\n",
    "\n",
    "\n",
    "for i in enfa['StateSet']:\n",
    "    e_match[tuple([i])] = [i]\n",
    "\n",
    "\n",
    "no_change = False\n",
    "while not no_change:\n",
    "    no_change = True\n",
    "    for delta in candidate: #single\n",
    "        if len(delta[0]) == 1 and delta[1] == 'ε' and len(e_match[tuple(delta[0])]) == 1:\n",
    "            e_match[tuple(delta[0])] = e_match[tuple(delta[0])]+delta[2] # ('q000',) : [\"q001\",\"q002\"]\n",
    "            if delta[0][0] not in e_match[tuple(delta[0])]: #본인 넣는다.\n",
    "                e_match[tuple(delta[0])].append(delta[0][0])\n",
    "            no_change = False\n",
    "        if len(delta[0]) == 1 and delta[1] == 'ε':\n",
    "            temp = deepcopy(e_match[tuple(delta[0])])\n",
    "            \n",
    "            for get in e_match[tuple(delta[0])]:\n",
    "                \n",
    "                if (get,) in e_match.keys(): \n",
    "                    temp = listunion(e_match[(get,)],temp)     \n",
    "            if len(temp) > len(e_match[tuple(delta[0])]):\n",
    "                e_match[tuple(delta[0])] = deepcopy(temp) \n",
    "                no_change = False\n",
    "\n",
    "def multcandidate(states):\n",
    "\n",
    "    for sigma in enfa['TerminalSet']:\n",
    "        if sigma != 'ε':\n",
    "            continue\n",
    "        q_temp = []\n",
    "        for state in states:\n",
    "            for key,val in enfa['DeltaFunctions'].items():\n",
    "                for value in val:\n",
    "                    start = key[1:5]\n",
    "                    inp = key[7]\n",
    "                    end = value\n",
    "                    if state == start and sigma == inp:\n",
    "                        if end not in q_temp:\n",
    "                            q_temp.append(end)\n",
    "        if not len(q_temp):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        q_states = states\n",
    "        q_states = sorted(q_states)\n",
    "        q_temp = sorted(q_temp)\n",
    "        candidate.append([q_states, sigma, q_temp])  \n",
    "\n",
    "    no_change = False\n",
    "    while not no_change:\n",
    "        no_change = True\n",
    "        for delta in candidate: #mult\n",
    "            \n",
    "            if len(delta[0]) != 1 and delta[1] == 'ε' and tuple(delta[0]) not in e_match.keys():\n",
    "                e_match[tuple(delta[0])] = deepcopy(delta[2]) # ('q000','q001') : [\"q001\",\"q002\"]\n",
    "                no_change = False\n",
    "            if len(delta[0]) != 1 and delta[1] == 'ε':\n",
    "                temp = deepcopy(e_match[tuple(delta[0])])\n",
    "                for d in delta[0]:\n",
    "                    for get in e_match[(d,)]:\n",
    "                        if (get,) in e_match.keys(): \n",
    "                            temp=listunion(e_match[(get,)],temp)\n",
    "                if len(temp) > len(e_match[tuple(delta[0])]):\n",
    "                    e_match[tuple(delta[0])] = deepcopy(temp) \n",
    "                    no_change = False\n",
    "\n",
    "\n",
    "\n",
    "new_candidate = []\n",
    "for ss in enfa['StartState']:\n",
    "    dfa['StartState'].add(tuple(sorted(e_match[(ss,)])))\n",
    "    dfa['StateSet'].add(tuple(sorted(e_match[(ss,)])))\n",
    "    no_change = False\n",
    "    have_to_do = []\n",
    "    have_to_do.append((ss,))\n",
    "    while len(have_to_do):\n",
    "        tg = have_to_do.pop()\n",
    "        \n",
    "        for sigma in enfa['TerminalSet']:\n",
    "            if sigma == 'ε':\n",
    "                continue\n",
    "            after_closer_result = []\n",
    "            \n",
    "            if tuple(tg) not in e_match.keys():\n",
    "                \n",
    "                multcandidate(tg)\n",
    "\n",
    "            for ecs in e_match[tuple(tg)]:\n",
    "                \n",
    "                result = get_enfa_delta(ecs, sigma)\n",
    "                if result:\n",
    "\n",
    "                    for r in result:\n",
    "                        if (r,) in e_match.keys():\n",
    "                            after_closer_result = listunion(after_closer_result, e_match[(r,)])\n",
    "            if not len(after_closer_result): # 결과가 없을떄\n",
    "                continue \n",
    "            if tuple(after_closer_result) not in dfa['StateSet']:\n",
    "                dfa['StateSet'].add(tuple(after_closer_result))\n",
    "                have_to_do.append(after_closer_result)\n",
    "            new_candidate.append([sorted(e_match[tuple(tg)]),sigma,sorted(after_closer_result)])\n",
    "\n",
    "\n",
    "\n",
    "for states in dfa['StateSet']:\n",
    "    for state in states:\n",
    "        if state in enfa['FinalStateSet'] and states not in dfa['FinalStateSet']:\n",
    "            dfa['FinalStateSet'].add(states)\n",
    "\n",
    "enfa['TerminalSet'].remove('ε')\n",
    "dfa['TerminalSet'] = deepcopy(enfa['TerminalSet'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['q000', 'q001', 'q002', 'q003', 'q004'],\n",
      "  'b',\n",
      "  ['q001', 'q002', 'q003', 'q004', 'q005', 'q006']],\n",
      " [['q000', 'q001', 'q002', 'q003', 'q004'],\n",
      "  'a',\n",
      "  ['q007', 'q008', 'q009', 'q010', 'q018']],\n",
      " [['q007', 'q008', 'q009', 'q010', 'q018'],\n",
      "  'b',\n",
      "  ['q001', 'q002', 'q003', 'q004', 'q006', 'q019']],\n",
      " [['q007', 'q008', 'q009', 'q010', 'q018'],\n",
      "  'a',\n",
      "  ['q011', 'q012', 'q013', 'q014', 'q016']],\n",
      " [['q011', 'q012', 'q013', 'q014', 'q016'],\n",
      "  'b',\n",
      "  ['q009', 'q010', 'q017', 'q018']],\n",
      " [['q011', 'q012', 'q013', 'q014', 'q016'],\n",
      "  'a',\n",
      "  ['q013', 'q014', 'q015', 'q016']],\n",
      " [['q013', 'q014', 'q015', 'q016'], 'b', ['q009', 'q010', 'q017', 'q018']],\n",
      " [['q013', 'q014', 'q015', 'q016'], 'a', ['q013', 'q014', 'q015', 'q016']],\n",
      " [['q009', 'q010', 'q017', 'q018'],\n",
      "  'b',\n",
      "  ['q001', 'q002', 'q003', 'q004', 'q006', 'q019']],\n",
      " [['q009', 'q010', 'q017', 'q018'],\n",
      "  'a',\n",
      "  ['q011', 'q012', 'q013', 'q014', 'q016']],\n",
      " [['q001', 'q002', 'q003', 'q004', 'q006', 'q019'],\n",
      "  'b',\n",
      "  ['q001', 'q002', 'q003', 'q004', 'q005', 'q006']],\n",
      " [['q001', 'q002', 'q003', 'q004', 'q006', 'q019'],\n",
      "  'a',\n",
      "  ['q007', 'q008', 'q009', 'q010', 'q018']],\n",
      " [['q001', 'q002', 'q003', 'q004', 'q005', 'q006'],\n",
      "  'b',\n",
      "  ['q001', 'q002', 'q003', 'q004', 'q005', 'q006']],\n",
      " [['q001', 'q002', 'q003', 'q004', 'q005', 'q006'],\n",
      "  'a',\n",
      "  ['q007', 'q008', 'q009', 'q010', 'q018']]]\n"
     ]
    }
   ],
   "source": [
    "pprint(new_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeltaFunctions': {},\n",
      " 'FinalStateSet': {('q000', 'q001', 'q002', 'q003', 'q004'),\n",
      "                   ('q001', 'q002', 'q003', 'q004', 'q005', 'q006'),\n",
      "                   ('q001', 'q002', 'q003', 'q004', 'q006', 'q019')},\n",
      " 'StartState': {('q000', 'q001', 'q002', 'q003', 'q004')},\n",
      " 'StateSet': {('q000', 'q001', 'q002', 'q003', 'q004'),\n",
      "              ('q001', 'q002', 'q003', 'q004', 'q005', 'q006'),\n",
      "              ('q001', 'q002', 'q003', 'q004', 'q006', 'q019'),\n",
      "              ('q007', 'q008', 'q009', 'q010', 'q018'),\n",
      "              ('q009', 'q010', 'q017', 'q018'),\n",
      "              ('q011', 'q012', 'q013', 'q014', 'q016'),\n",
      "              ('q013', 'q014', 'q015', 'q016')},\n",
      " 'TerminalSet': {'b', 'a'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('q009', 'q010', 'q017', 'q018'): 'q000', ('q001', 'q002', 'q003', 'q004', 'q005', 'q006'): 'q001', ('q007', 'q008', 'q009', 'q010', 'q018'): 'q002', ('q013', 'q014', 'q015', 'q016'): 'q003', ('q001', 'q002', 'q003', 'q004', 'q006', 'q019'): 'q004', ('q011', 'q012', 'q013', 'q014', 'q016'): 'q005', ('q000', 'q001', 'q002', 'q003', 'q004'): 'q006'}\n"
     ]
    }
   ],
   "source": [
    "reduce_table = {}\n",
    "for i,v in enumerate(dfa['StateSet']):\n",
    "    val = \"q\"+sonbug_numbering(i)\n",
    "    reduce_table[v] = val\n",
    "print(reduce_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for delta in new_candidate:\n",
    "    dfa['DeltaFunctions'][\"(\"+reduce_table[tuple(sorted(delta[0]))]+\", \"+delta[1]+\")\"] = {reduce_table[tuple(sorted(delta[2]))]}\n",
    "\n",
    "sett = set()\n",
    "sett.add(reduce_table[list(dfa['StartState'])[0]])\n",
    "\n",
    "dfa['StartState'] = deepcopy(sett)\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for state in dfa['StateSet']:\n",
    "    sett.add(reduce_table[state])\n",
    "    \n",
    "dfa['StateSet'] = deepcopy(sett)\n",
    "\n",
    "sett = set()\n",
    "\n",
    "for state in dfa['FinalStateSet']:\n",
    "    sett.add(reduce_table[state])\n",
    "dfa['FinalStateSet'] = sett\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeltaFunctions': {'(q000, a)': {'q005'},\n",
      "                    '(q000, b)': {'q004'},\n",
      "                    '(q001, a)': {'q002'},\n",
      "                    '(q001, b)': {'q001'},\n",
      "                    '(q002, a)': {'q005'},\n",
      "                    '(q002, b)': {'q004'},\n",
      "                    '(q003, a)': {'q003'},\n",
      "                    '(q003, b)': {'q000'},\n",
      "                    '(q004, a)': {'q002'},\n",
      "                    '(q004, b)': {'q001'},\n",
      "                    '(q005, a)': {'q003'},\n",
      "                    '(q005, b)': {'q000'},\n",
      "                    '(q006, a)': {'q002'},\n",
      "                    '(q006, b)': {'q001'}},\n",
      " 'FinalStateSet': {'q004', 'q001', 'q006'},\n",
      " 'StartState': {'q006'},\n",
      " 'StateSet': {'q004', 'q000', 'q001', 'q006', 'q003', 'q005', 'q002'},\n",
      " 'TerminalSet': {'b', 'a'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dfa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFA -> reduced DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfa_delta(state, input):\n",
    "    if \"(\"+state+\", \"+input+\")\" in dfa['DeltaFunctions'].keys():\n",
    "        return list(dfa['DeltaFunctions'][\"(\"+state+\", \"+input+\")\"])[0]\n",
    "    return \"-1\"\n",
    "\n",
    "def something_in_list(something, list):\n",
    "    if something in list:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def combine_same_inlist(lst):\n",
    "    pass\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['q005', 'q003'], ['q002', 'q000'], ['q001', 'q004', 'q006']]\n",
      "[defaultdict(<class 'list'>, {'10': ['q005', 'q003']}), defaultdict(<class 'list'>, {'20': ['q002', 'q000']}), defaultdict(<class 'list'>, {'21': ['q001', 'q004', 'q006']})]\n"
     ]
    }
   ],
   "source": [
    "new_candidate = []\n",
    "\n",
    "getarr=sorted(list(dfa['StateSet']))\n",
    "\n",
    "arr = [list(dfa['StateSet'] - dfa['FinalStateSet']),sorted(list(dfa['FinalStateSet']))]\n",
    "LEN_STATE = len(dfa['StateSet'])\n",
    "checkarr = [[\"I\"]*len(dfa['TerminalSet']) for _ in range(LEN_STATE)]\n",
    "\n",
    "for i in range(LEN_STATE+1):\n",
    "    lenarr = len(arr)\n",
    "    for j in range(LEN_STATE):\n",
    "        for ki,kv in enumerate(dfa['TerminalSet']):\n",
    "            anstr=get_dfa_delta(getarr[j],kv)\n",
    "            \n",
    "            \n",
    "            if anstr==\"-1\":\n",
    "                checkarr[j][ki] = \"N\"\n",
    "            else:\n",
    "                for mi,mv in enumerate(arr):\n",
    "                    if something_in_list(anstr,mv):\n",
    "                        checkarr[j][ki] = str(mi)\n",
    "    temp_arr = []\n",
    "\n",
    "    \n",
    "    big_ddic = []\n",
    "    for ji,jv in enumerate(arr):\n",
    "        ddic = defaultdict(list)\n",
    "        for ki,kv in enumerate(jv):\n",
    "            sumstr = \"\"\n",
    "            for m in checkarr[int(kv[1:])]:\n",
    "                sumstr += m\n",
    "            ddic[sumstr].append(kv)\n",
    "        \n",
    "        for key,val in ddic.items():\n",
    "            temp_arr.append(val)\n",
    "        big_ddic.append(deepcopy(ddic))\n",
    "        \n",
    "\n",
    "\n",
    "    arr = deepcopy(temp_arr)    \n",
    "    \n",
    "    \n",
    "    if lenarr == len(arr):\n",
    "        print(arr)\n",
    "        print(big_ddic)\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in big_ddic:\n",
    "    for k,v in i.items():\n",
    "        for ji,jv in enumerate(dfa['TerminalSet']):\n",
    "            #v가 jv를 보고 arr[k[ji]]로 이동한다는 것임\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q004': 'q000', 'q000': 'q001', 'q001': 'q002', 'q006': 'q003', 'q003': 'q004', 'q005': 'q005', 'q002': 'q006'}\n"
     ]
    }
   ],
   "source": [
    "reduce_table = {}\n",
    "for i,v in enumerate(dfa['StateSet']):\n",
    "    val = \"q\"+sonbug_numbering(i)\n",
    "    reduce_table[v] = val\n",
    "print(reduce_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multvenv",
   "language": "python",
   "name": "multvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
